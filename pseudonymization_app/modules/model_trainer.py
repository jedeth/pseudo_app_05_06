# Fichier : modules/model_trainer.py

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Module d'entra√Ænement de mod√®les SpaCy pour NER personnalis√©
===========================================================

Ce module g√®re le fine-tuning de mod√®les SpaCy existants.
Version corrig√©e et stabilis√©e.
"""

import spacy
from spacy.training import Example
from spacy.util import minibatch, compounding
import random
import json
import time
from pathlib import Path
from typing import List, Dict, Tuple, Callable, Any
from datetime import datetime
import traceback

class SpacyModelTrainer:
    """
    Gestionnaire d'entra√Ænement pour les mod√®les SpaCy NER personnalis√©s.
    """
    
    def __init__(self, base_model_name: str = "fr_core_news_sm"):
        """ Initialise le trainer avec un mod√®le de base. """
        self.base_model_name = base_model_name
        self.nlp = None
        self.ner = None
        self.training_history = []
        self.custom_entities = []
        self.default_config = {
            'n_iter': 30, 'dropout': 0.2, 'batch_size': 8,
            'patience': 5, 'validation_split': 0.2
        }
        print(f"ü§ñ Trainer initialis√© avec le mod√®le de base : {base_model_name}")
    
    def load_base_model(self) -> bool:
        """ Charge le mod√®le SpaCy de base et pr√©pare le composant NER. """
        try:
            print(f"üì• Chargement du mod√®le de base : {self.base_model_name}")
            self.nlp = spacy.load(self.base_model_name)
            
            if "ner" in self.nlp.pipe_names:
                self.ner = self.nlp.get_pipe("ner")
            else:
                self.ner = self.nlp.add_pipe("ner", last=True)
                
            print("‚úÖ Mod√®le de base charg√© et composant NER pr√™t.")
            return True
        except OSError:
            print(f"‚ùå ERREUR : Le mod√®le '{self.base_model_name}' n'est pas install√©.")
            print(f"üí° Essayez : python -m spacy download {self.base_model_name}")
            return False
        except Exception as e:
            print(f"‚ùå Erreur lors du chargement du mod√®le : {e}")
            return False
    
    def add_custom_entities(self, entity_types: List[str]) -> bool:
        """ Ajoute de nouvelles √©tiquettes d'entit√©s au composant NER. """
        if not self.ner:
            print("‚ùå Le composant NER n'est pas initialis√©. Chargez d'abord un mod√®le.")
            return False
        
        print(f"üè∑Ô∏è  Ajout des entit√©s personnalis√©es : {entity_types}")
        for entity_type in entity_types:
            if entity_type not in self.ner.labels:
                self.ner.add_label(entity_type)
        
        self.custom_entities = list(self.ner.labels)
        print(f"üéØ Entit√©s configur√©es dans le mod√®le : {self.custom_entities}")
        return True
    
    def prepare_training_data(self, raw_training_data: List[Tuple[str, Dict]]) -> List[Example]:
        """ Pr√©pare les donn√©es brutes au format SpaCy Example. """
        examples = []
        print(f"üîÑ Pr√©paration de {len(raw_training_data)} exemples...")
        for text, annotations in raw_training_data:
            try:
                doc = self.nlp.make_doc(text)
                example = Example.from_dict(doc, annotations)
                examples.append(example)
            except Exception as e:
                print(f"‚ö†Ô∏è Erreur de pr√©paration pour l'exemple '{text[:50]}...' : {e}")
        print(f"‚úÖ {len(examples)} exemples pr√©par√©s avec succ√®s.")
        return examples
    
    def split_data(self, examples: List[Example], validation_split: float) -> Tuple[List[Example], List[Example]]:
        """ Divise les donn√©es en ensembles d'entra√Ænement et de validation. """
        random.shuffle(examples)
        val_size = int(len(examples) * validation_split)
        train_examples = examples[val_size:]
        val_examples = examples[:val_size]
        print(f"üìä Donn√©es divis√©es : {len(train_examples)} entra√Ænement, {len(val_examples)} validation.")
        return train_examples, val_examples
    
    def evaluate_model(self, examples: List[Example]) -> Dict[str, float]:
        """ √âvalue les performances du mod√®le sur un ensemble de donn√©es. """
        if not examples:
            return {"ents_p": 0.0, "ents_r": 0.0, "ents_f": 0.0}
        return self.nlp.evaluate(examples)

    def train_model(self, training_data: List[Tuple[str, Dict]], 
                   config: Dict[str, Any] = None,
                   progress_callback: Callable[[int, int, Dict], None] = None) -> Dict[str, Any]:
        """
        Effectue l'entra√Ænement du mod√®le avec la logique corrig√©e.
        """
        if config is None:
            config = self.default_config.copy()
        
        print(f"üöÄ D√©but de l'entra√Ænement avec la configuration : {config}")
        
        try:
            examples = self.prepare_training_data(training_data)
            if not examples:
                raise ValueError("Aucun exemple valide pour l'entra√Ænement.")
            
            train_examples, val_examples = self.split_data(
                examples, config.get('validation_split', 0.2)
            )
            
            self.training_history = []
            best_f1_score = -1.0
            patience_counter = 0
            best_model_state = None
            
            other_pipes = [pipe for pipe in self.nlp.pipe_names if pipe != "ner"]
            with self.nlp.disable_pipes(*other_pipes):
                optimizer = self.nlp.resume_training()
                
                print(f"üéØ Boucle d'entra√Ænement d√©marr√©e pour {config.get('n_iter', 30)} √©poques.")
                
                for epoch in range(config.get('n_iter', 30)):
                    start_time = time.time()
                    random.shuffle(train_examples)
                    losses = {}
                    
                    # Utilisation correcte du g√©n√©rateur de taille de lots
                    batch_sizes_generator = compounding(
                        config.get('batch_size', 4.0), 
                        32.0,
                        1.001
                    )
                    
                    for batch in minibatch(train_examples, size=batch_sizes_generator):
                        self.nlp.update(
                            batch, 
                            drop=config.get('dropout', 0.2),
                            losses=losses,
                            sgd=optimizer
                        )
                    
                    val_scores = self.evaluate_model(val_examples)
                    current_f1 = val_scores.get("ents_f", 0.0)
                    epoch_time = time.time() - start_time
                    
                    epoch_info = {
                        'epoch': epoch + 1,
                        'train_loss': losses.get('ner', 0.0),
                        'val_f1': current_f1,
                        'epoch_time': epoch_time
                    }
                    self.training_history.append(epoch_info)
                    
                    if progress_callback:
                        progress_callback(epoch + 1, config.get('n_iter', 30), epoch_info)
                    
                    # Early stopping pour √©viter le sur-entra√Ænement
                    if current_f1 > best_f1_score:
                        best_f1_score = current_f1
                        patience_counter = 0
                        best_model_state = self.nlp.to_bytes()
                    else:
                        patience_counter += 1
                    
                    if patience_counter >= config.get('patience', 5) and epoch > 10:
                        print(f"üõë Arr√™t anticip√© apr√®s {epoch + 1} √©poques.")
                        break
            
            if best_model_state:
                print(f"‚úÖ Restauration du meilleur mod√®le (F1-score : {best_f1_score:.3f}).")
                self.nlp.from_bytes(best_model_state)
            
            final_metrics = self.evaluate_model(val_examples)
            
            return {
                'success': True,
                'epochs_completed': len(self.training_history),
                'final_metrics': {
                    "precision": final_metrics.get("ents_p", 0.0),
                    "recall": final_metrics.get("ents_r", 0.0),
                    "f1": final_metrics.get("ents_f", 0.0)
                }
            }
            
        except Exception as e:
            print(f"‚ùå Erreur majeure dans train_model : {e}")
            traceback.print_exc() # Imprime une trace d√©taill√©e de l'erreur dans la console
            return {'success': False, 'error': str(e)}

    def save_model(self, output_path: str, model_info: Dict[str, Any] = None) -> str:
        """ Sauvegarde le mod√®le entra√Æn√© sur le disque. """
        output_dir = Path(output_path)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        self.nlp.to_disk(output_dir)
        
        metadata = {
            'base_model': self.base_model_name,
            'custom_entities': self.custom_entities,
            'training_date': datetime.now().isoformat(),
            'model_info': model_info or {}
        }
        with open(output_dir / "model_metadata.json", 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2)
            
        print(f"üíæ Mod√®le sauvegard√© dans : {output_dir}")
        return str(output_dir)
    
    def load_trained_model(self, model_path: str) -> bool:
        """ Charge un mod√®le pr√©c√©demment entra√Æn√©. """
        try:
            self.nlp = spacy.load(model_path)
            print(f"‚úÖ Mod√®le charg√© depuis : {model_path}")
            return True
        except Exception as e:
            print(f"‚ùå Erreur lors du chargement du mod√®le depuis {model_path} : {e}")
            return False
    
    def get_model_info(self) -> Dict[str, Any]:
        """ Retourne des informations sur le mod√®le actuellement charg√©. """
        if not self.nlp:
            return {"status": "Aucun mod√®le charg√©"}
        
        return {
            "base_model": self.base_model_name,
            "custom_entities": self.nlp.get_pipe("ner").labels,
            "pipeline_components": self.nlp.pipe_names,
        }
    
    def test_model(self, test_text: str) -> Dict[str, Any]:
        """ Teste le mod√®le sur un texte donn√©. """
        if not self.nlp:
            return {"error": "Aucun mod√®le charg√©.", "processed_successfully": False}
        
        try:
            doc = self.nlp(test_text)
            entities = [{"text": ent.text, "label": ent.label_} for ent in doc.ents]
            return {"entities": entities, "processed_successfully": True}
        except Exception as e:
            return {"error": str(e), "processed_successfully": False}