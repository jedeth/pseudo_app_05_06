#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Module d'entra√Ænement de mod√®les SpaCy pour NER personnalis√©
===========================================================

Ce module g√®re le fine-tuning de mod√®les SpaCy existants avec de nouvelles
entit√©s NER personnalis√©es. Il inclut la gestion des callbacks de progression,
l'√©valuation des performances et la sauvegarde des mod√®les entra√Æn√©s.
"""

import spacy
from spacy.training import Example
from spacy.util import minibatch, compounding
import random
import json
import time
from pathlib import Path
from typing import List, Dict, Tuple, Callable, Optional, Any
import numpy as np
from datetime import datetime
import pickle

class SpacyModelTrainer:
    """
    Gestionnaire d'entra√Ænement pour les mod√®les SpaCy NER personnalis√©s
    
    Cette classe permet de :
    - Charger un mod√®le SpaCy de base
    - Ajouter de nouvelles entit√©s NER
    - Effectuer le fine-tuning avec suivi des performances
    - Sauvegarder les mod√®les entra√Æn√©s
    """
    
    def __init__(self, base_model_name: str = "fr_core_news_sm"):
        """
        Initialise le trainer avec un mod√®le de base
        
        Args:
            base_model_name (str): Nom du mod√®le SpaCy de base √† utiliser
        """
        self.base_model_name = base_model_name
        self.nlp = None
        self.ner = None
        self.training_history = []
        self.custom_entities = []
        
        # Param√®tres d'entra√Ænement par d√©faut
        self.default_config = {
            'n_iter': 30,
            'dropout': 0.2,
            'batch_size': 8,
            'learn_rate': 0.001,
            'patience': 5,  # Pour l'early stopping
            'validation_split': 0.2
        }
        
        print(f"ü§ñ Trainer initialis√© avec le mod√®le de base: {base_model_name}")
    
    def load_base_model(self) -> bool:
        """
        Charge le mod√®le SpaCy de base
        
        Returns:
            bool: True si le chargement a r√©ussi, False sinon
        """
        try:
            print(f"üì• Chargement du mod√®le de base: {self.base_model_name}")
            
            # Tente de charger le mod√®le
            self.nlp = spacy.load(self.base_model_name)
            
            # Obtient le composant NER
            if "ner" in self.nlp.pipe_names:
                self.ner = self.nlp.get_pipe("ner")
                print("‚úÖ Composant NER trouv√© dans le mod√®le")
            else:
                # Cr√©e un nouveau composant NER si absent
                self.ner = self.nlp.add_pipe("ner", last=True)
                print("üÜï Nouveau composant NER cr√©√©")
            
            return True
            
        except OSError as e:
            print(f"‚ùå Erreur: Le mod√®le '{self.base_model_name}' n'est pas install√©")
            print(f"üí° Installez-le avec: python -m spacy download {self.base_model_name}")
            return False
        except Exception as e:
            print(f"‚ùå Erreur lors du chargement du mod√®le: {e}")
            return False
    
    def add_custom_entities(self, entity_types: List[str]) -> bool:
        """
        Ajoute de nouvelles √©tiquettes d'entit√©s au mod√®le
        
        Args:
            entity_types (List[str]): Liste des nouveaux types d'entit√©s
            
        Returns:
            bool: True si l'ajout a r√©ussi, False sinon
        """
        if not self.nlp or not self.ner:
            print("‚ùå Mod√®le de base non charg√©")
            return False
        
        try:
            print(f"üè∑Ô∏è Ajout des entit√©s personnalis√©es: {entity_types}")
            
            for entity_type in entity_types:
                # Ajoute l'√©tiquette au composant NER
                self.ner.add_label(entity_type)
                self.custom_entities.append(entity_type)
                print(f"  ‚úÖ Entit√© ajout√©e: {entity_type}")
            
            print(f"üéØ {len(entity_types)} nouvelles entit√©s configur√©es")
            return True
            
        except Exception as e:
            print(f"‚ùå Erreur lors de l'ajout des entit√©s: {e}")
            return False
    
    def prepare_training_data(self, raw_training_data: List[Tuple[str, Dict]]) -> List[Example]:
        """
        Pr√©pare les donn√©es d'entra√Ænement au format SpaCy Example
        
        Args:
            raw_training_data: Donn√©es brutes (texte, annotations)
            
        Returns:
            List[Example]: Donn√©es au format SpaCy Example
        """
        examples = []
        
        print(f"üîÑ Pr√©paration de {len(raw_training_data)} exemples d'entra√Ænement...")
        
        for text, annotations in raw_training_data:
            try:
                # Cr√©e un document SpaCy
                doc = self.nlp.make_doc(text)
                
                # Cr√©e l'exemple d'entra√Ænement
                example = Example.from_dict(doc, annotations)
                examples.append(example)
                
            except Exception as e:
                print(f"‚ö†Ô∏è Erreur avec l'exemple '{text[:50]}...': {e}")
                continue
        
        print(f"‚úÖ {len(examples)} exemples pr√©par√©s avec succ√®s")
        return examples
    
    def split_data(self, examples: List[Example], validation_split: float = 0.2) -> Tuple[List[Example], List[Example]]:
        """
        Divise les donn√©es en ensembles d'entra√Ænement et de validation
        
        Args:
            examples: Liste des exemples
            validation_split: Proportion pour la validation
            
        Returns:
            Tuple: (donn√©es d'entra√Ænement, donn√©es de validation)
        """
        # M√©lange les donn√©es
        random.shuffle(examples)
        
        # Calcule la taille de validation
        val_size = int(len(examples) * validation_split)
        
        # Divise les donn√©es
        train_examples = examples[val_size:]
        val_examples = examples[:val_size]
        
        print(f"üìä Donn√©es divis√©es: {len(train_examples)} entra√Ænement, {len(val_examples)} validation")
        
        return train_examples, val_examples
    
    def evaluate_model(self, examples: List[Example]) -> Dict[str, float]:
        """
        √âvalue les performances du mod√®le sur un ensemble de donn√©es
        
        Args:
            examples: Exemples √† √©valuer
            
        Returns:
            Dict: M√©triques de performance (pr√©cision, rappel, F1-score)
        """
        if not examples:
            return {"precision": 0.0, "recall": 0.0, "f1": 0.0}
        
        scores = self.nlp.evaluate(examples)
        
        # Extrait les m√©triques principales
        metrics = {
            "precision": scores.get("ents_p", 0.0),
            "recall": scores.get("ents_r", 0.0), 
            "f1": scores.get("ents_f", 0.0),
            "accuracy": scores.get("token_acc", 0.0)
        }
        
        return metrics
    
    def train_model(self, training_data: List[Tuple[str, Dict]], 
                   config: Dict[str, Any] = None,
                   progress_callback: Callable[[int, int, Dict], None] = None) -> Dict[str, Any]:
        """
        Effectue l'entra√Ænement du mod√®le avec suivi des performances
        
        Args:
            training_data: Donn√©es d'entra√Ænement brutes
            config: Configuration d'entra√Ænement
            progress_callback: Fonction de callback pour le suivi
            
        Returns:
            Dict: R√©sultats d'entra√Ænement et m√©triques finales
        """
        # Utilise la configuration par d√©faut si non fournie
        if config is None:
            config = self.default_config.copy()
        
        print(f"üöÄ D√©but de l'entra√Ænement avec {len(training_data)} exemples")
        print(f"‚öôÔ∏è Configuration: {config}")
        
        try:
            # Pr√©pare les donn√©es
            examples = self.prepare_training_data(training_data)
            if not examples:
                raise ValueError("Aucun exemple valide pour l'entra√Ænement")
            
            # Divise les donn√©es
            train_examples, val_examples = self.split_data(
                examples, config.get('validation_split', 0.2)
            )
            
            # Initialise l'historique d'entra√Ænement
            self.training_history = []
            best_f1 = 0.0
            patience_counter = 0
            best_model_state = None
            
            # Configuration des tailles de batch dynamiques
            batch_sizes = compounding(
                config.get('batch_size', 8), 
                config.get('batch_size', 8) * 2, 
                1.001
            )
            
            # D√©sactive les autres composants pendant l'entra√Ænement
            other_pipes = [pipe for pipe in self.nlp.pipe_names if pipe != "ner"]
            with self.nlp.disable_pipes(*other_pipes):
                
                # Obtient l'optimizer
                optimizer = self.nlp.resume_training()
                
                print(f"üéØ D√©but de l'entra√Ænement ({config.get('n_iter', 30)} √©poques)")
                
                for epoch in range(config.get('n_iter', 30)):
                    start_time = time.time()
                    
                    # M√©lange les donn√©es d'entra√Ænement
                    random.shuffle(train_examples)
                    
                    # Variables pour le suivi des pertes
                    losses = {}
                    batches_processed = 0
                    
                    # Entra√Ænement par batch
                    for batch in minibatch(train_examples, size=next(batch_sizes)):
                        self.nlp.update(
                            batch, 
                            drop=config.get('dropout', 0.2),
                            losses=losses,
                            sgd=optimizer
                        )
                        batches_processed += 1
                    
                    # √âvaluation sur les donn√©es de validation
                    train_metrics = self.evaluate_model(train_examples[:100])  # Sous-ensemble pour la vitesse
                    val_metrics = self.evaluate_model(val_examples)
                    
                    epoch_time = time.time() - start_time
                    
                    # Enregistre les m√©triques
                    epoch_info = {
                        'epoch': epoch + 1,
                        'train_loss': losses.get('ner', 0.0),
                        'train_precision': train_metrics['precision'],
                        'train_recall': train_metrics['recall'],
                        'train_f1': train_metrics['f1'],
                        'val_precision': val_metrics['precision'],
                        'val_recall': val_metrics['recall'],
                        'val_f1': val_metrics['f1'],
                        'epoch_time': epoch_time,
                        'batches_processed': batches_processed
                    }
                    
                    self.training_history.append(epoch_info)
                    
                    # Affichage des m√©triques
                    print(f"√âpoque {epoch + 1:2d}/{config.get('n_iter', 30)} | "
                          f"Loss: {losses.get('ner', 0.0):.4f} | "
                          f"Val F1: {val_metrics['f1']:.3f} | "
                          f"Temps: {epoch_time:.1f}s")
                    
                    # Callback de progression
                    if progress_callback:
                        progress_callback(epoch + 1, config.get('n_iter', 30), epoch_info)
                    
                    # Early stopping
                    current_f1 = val_metrics['f1']
                    if current_f1 > best_f1:
                        best_f1 = current_f1
                        patience_counter = 0
                        # Sauvegarde le meilleur √©tat du mod√®le
                        best_model_state = self.nlp.to_bytes()
                        print(f"  üéâ Nouveau meilleur F1-score: {best_f1:.3f}")
                    else:
                        patience_counter += 1
                    
                    # Arr√™t anticip√© si pas d'am√©lioration
                    if patience_counter >= config.get('patience', 5) and epoch > 10:
                        print(f"üõë Arr√™t anticip√© apr√®s {patience_counter} √©poques sans am√©lioration")
                        break
            
            # Restaure le meilleur mod√®le
            if best_model_state:
                self.nlp.from_bytes(best_model_state)
                print(f"‚úÖ Meilleur mod√®le restaur√© (F1-score: {best_f1:.3f})")
            
            # √âvaluation finale
            final_metrics = self.evaluate_model(val_examples)
            
            training_results = {
                'success': True,
                'epochs_completed': len(self.training_history),
                'best_f1_score': best_f1,
                'final_metrics': final_metrics,
                'training_history': self.training_history,
                'config_used': config
            }
            
            print(f"üèÅ Entra√Ænement termin√© avec succ√®s!")
            print(f"üìä M√©triques finales: P={final_metrics['precision']:.3f}, "
                  f"R={final_metrics['recall']:.3f}, F1={final_metrics['f1']:.3f}")
            
            return training_results
            
        except Exception as e:
            print(f"‚ùå Erreur pendant l'entra√Ænement: {e}")
            return {
                'success': False,
                'error': str(e),
                'training_history': self.training_history
            }
    
    def save_model(self, output_path: str = None, 
                   model_info: Dict[str, Any] = None) -> str:
        """
        Sauvegarde le mod√®le entra√Æn√©
        
        Args:
            output_path: Chemin de sauvegarde (g√©n√©r√© automatiquement si None)
            model_info: Informations suppl√©mentaires sur le mod√®le
            
        Returns:
            str: Chemin du mod√®le sauvegard√©
        """
        if not self.nlp:
            raise ValueError("Aucun mod√®le √† sauvegarder")
        
        # G√©n√®re un nom de fichier si non fourni
        if output_path is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_path = f"models/spacy_model_{timestamp}"
        
        # Cr√©e le dossier de destination
        output_dir = Path(output_path)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        try:
            # Sauvegarde le mod√®le SpaCy
            self.nlp.to_disk(output_dir)
            
            # Sauvegarde les m√©tadonn√©es
            metadata = {
                'base_model': self.base_model_name,
                'custom_entities': self.custom_entities,
                'training_date': datetime.now().isoformat(),
                'training_history': self.training_history[-5:] if self.training_history else [],  # Derni√®res √©poques
                'model_info': model_info or {}
            }
            
            metadata_path = output_dir / "model_metadata.json"
            with open(metadata_path, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False)
            
            # Sauvegarde l'historique complet d'entra√Ænement
            if self.training_history:
                history_path = output_dir / "training_history.json"
                with open(history_path, 'w', encoding='utf-8') as f:
                    json.dump(self.training_history, f, indent=2)
            
            print(f"üíæ Mod√®le sauvegard√© dans: {output_dir}")
            print(f"üìã M√©tadonn√©es sauvegard√©es: {metadata_path}")
            
            return str(output_dir)
            
        except Exception as e:
            raise Exception(f"Erreur lors de la sauvegarde: {e}")
    
    def load_trained_model(self, model_path: str) -> bool:
        """
        Charge un mod√®le pr√©c√©demment entra√Æn√©
        
        Args:
            model_path: Chemin vers le mod√®le sauvegard√©
            
        Returns:
            bool: True si le chargement a r√©ussi
        """
        try:
            model_dir = Path(model_path)
            
            if not model_dir.exists():
                raise FileNotFoundError(f"Le mod√®le {model_path} n'existe pas")
            
            # Charge le mod√®le
            self.nlp = spacy.load(model_dir)
            
            # Charge les m√©tadonn√©es si disponibles
            metadata_path = model_dir / "model_metadata.json"
            if metadata_path.exists():
                with open(metadata_path, 'r', encoding='utf-8') as f:
                    metadata = json.load(f)
                
                self.base_model_name = metadata.get('base_model', 'unknown')
                self.custom_entities = metadata.get('custom_entities', [])
                
                print(f"üìã M√©tadonn√©es charg√©es: {len(self.custom_entities)} entit√©s personnalis√©es")
            
            print(f"‚úÖ Mod√®le charg√© depuis: {model_path}")
            return True
            
        except Exception as e:
            print(f"‚ùå Erreur lors du chargement du mod√®le: {e}")
            return False
    
    def get_model_info(self) -> Dict[str, Any]:
        """
        Retourne les informations sur le mod√®le actuel
        
        Returns:
            Dict: Informations d√©taill√©es sur le mod√®le
        """
        if not self.nlp:
            return {"status": "no_model_loaded"}
        
        info = {
            "base_model": self.base_model_name,
            "custom_entities": self.custom_entities,
            "pipeline_components": self.nlp.pipe_names,
            "vocab_size": len(self.nlp.vocab),
            "has_ner": "ner" in self.nlp.pipe_names,
            "training_epochs": len(self.training_history),
            "status": "ready"
        }
        
        if self.training_history:
            last_epoch = self.training_history[-1]
            info["last_performance"] = {
                "f1_score": last_epoch.get('val_f1', 0.0),
                "precision": last_epoch.get('val_precision', 0.0),
                "recall": last_epoch.get('val_recall', 0.0)
            }
        
        return info
    
    def test_model(self, test_text: str) -> Dict[str, Any]:
        """
        Teste le mod√®le sur un texte donn√©
        
        Args:
            test_text: Texte √† analyser
            
        Returns:
            Dict: R√©sultats de l'analyse NER
        """
        if not self.nlp:
            return {"error": "Aucun mod√®le charg√©"}
        
        try:
            doc = self.nlp(test_text)
            
            entities = []
            for ent in doc.ents:
                entities.append({
                    "text": ent.text,
                    "label": ent.label_,
                    "start": ent.start_char,
                    "end": ent.end_char,
                    "confidence": getattr(ent, "_.confidence", 1.0)  # Si disponible
                })
            
            return {
                "text": test_text,
                "entities": entities,
                "entity_count": len(entities),
                "processed_successfully": True
            }
            
        except Exception as e:
            return {
                "error": f"Erreur lors du test: {e}",
                "processed_successfully": False
            }